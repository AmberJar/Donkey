{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "##library required\n",
    "from wildlife_datasets.datasets import MacaqueFaces\n",
    "from wildlife_tools.data import WildlifeDataset\n",
    "import torchvision.transforms as T\n",
    "import timm\n",
    "from wildlife_tools.features import DeepFeatures\n",
    "from wildlife_tools.inference import KnnMatcher\n",
    "from wildlife_tools.data import FeatureDatabase\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# 加载权重文件路径\n",
    "model_path = \"/data/Jar/projects/ultralytics/ultralytics/runs/detect/yolov8_large/weights/best.pt\"\n",
    "model = YOLO(model_path)  # 加载自定义模型\n",
    "\n",
    "# 预测\n",
    "original_image = '/data/Elio/data/Donkeys/trainset/origin_Data/images/Daphne_00012.jpg'\n",
    "results = model.predict(original_image, conf=0.25)  # 不使用 source 参数\n",
    "\n",
    "# 打印结果\n",
    "print(results)\n",
    "\n",
    "# 提取并打印每个边界框的信息\n",
    "for result in results:\n",
    "    boxes = result.boxes  # 获取所有边界框\n",
    "    for box in boxes:\n",
    "        # 获取边界框的坐标\n",
    "        bbox = box.xyxy[0].tolist()  # 转换为 [x_min, y_min, x_max, y_max] 格式\n",
    "        confidence = box.conf[0].item()  # 置信度\n",
    "        class_id = int(box.cls[0].item())  # 类别ID\n",
    "        print(f\"BBox: {bbox}, Confidence: {confidence}, Class ID: {class_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from torchvision import transforms\n",
    "\n",
    "class DonkeyDataset:\n",
    "    def __init__(self, root, label, transform=None, register=False):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        # 获取所有图片文件的路径\n",
    "        self.image_files = sorted([f for f in os.listdir(root) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        self.register = register\n",
    "        self.label_path = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def get_image(self, path):\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(img)\n",
    "        return img\n",
    "    \n",
    "    # YOLO 格式的 bbox: [x_center, y_center, width, height] （归一化坐标）\n",
    "    # width 和 height 是图像的宽度和高度（像素）\n",
    "    def yolo_to_pixel(self, bbox, img_width, img_height):\n",
    "        x_center, y_center, w, h = bbox\n",
    "\n",
    "        # 反归一化为像素坐标\n",
    "        x_center *= img_width\n",
    "        y_center *= img_height\n",
    "        w *= img_width\n",
    "        h *= img_height\n",
    "\n",
    "        # 计算像素坐标边界框 (x_min, y_min, x_max, y_max)\n",
    "        x_min = x_center - w / 2\n",
    "        y_min = y_center - h / 2\n",
    "        x_max = x_center + w / 2\n",
    "        y_max = y_center + h / 2\n",
    "\n",
    "        # 确保坐标在图像范围内\n",
    "        x_min = max(0, min(img_width, round(x_min)))\n",
    "        y_min = max(0, min(img_height, round(y_min)))\n",
    "        x_max = max(0, min(img_width, round(x_max)))\n",
    "        y_max = max(0, min(img_height, round(y_max)))\n",
    "\n",
    "        return x_min, y_min, x_max, y_max\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_files[idx]\n",
    "        label_name = os.path.splitext(image_name)[0] + '.txt'\n",
    "        img_path = os.path.join(self.root, image_name)\n",
    "\n",
    "        # 提取标签 (根据文件名分割方式，你可以调整 label 提取逻辑)\n",
    "        label = image_name.split(',')[0]  # 或者根据你的命名规则来提取\n",
    "        \n",
    "        if not self.register:\n",
    "            print('1')\n",
    "            # 加载图片\n",
    "            img = self.get_image(img_path)\n",
    "\n",
    "            # 应用 transform\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "        else:\n",
    "            #print('2')\n",
    "            original_image = Image.open(img_path).convert(\"RGB\")  # 转换为 PIL 图像\n",
    "            width, height = original_image.size\n",
    "            bbox = None\n",
    "\n",
    "            with open(os.path.join(self.label_path, label_name), 'r') as file:\n",
    "                for line in file:\n",
    "                    # 解析每一行的数据\n",
    "                    values = line.strip().split()\n",
    "                    class_id = int(values[0])  # 第一个数是类别\n",
    "                    bbox = list(map(float, values[1:5]))  # 后四个数是边框坐标\n",
    "                    #print(f\"Class ID: {class_id}, Bounding Box: {bbox}\")\n",
    "\n",
    "            x_min, y_min, x_max, y_max = self.yolo_to_pixel(bbox, width, height)\n",
    "            #print(x_min, y_min, x_max, y_max)\n",
    "            # 裁剪原图中的边界框区域\n",
    "            cropped_image = original_image.crop((x_min, y_min, x_max, y_max))\n",
    "            #cropped_image.save(image_name)\n",
    "            #cropped_image.show()\n",
    "            # 应用图像变换\n",
    "            img = self.transform(cropped_image)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 创建测试数据\n",
    "root = '/data/Elio/data/Donkeys/trainset/origin_Data/images'  # 假设这是文件名列表，包含路径和标签\n",
    "label = '/data/Elio/data/Donkeys/donkey_labels_rec'\n",
    "dataset_root_path = root  # 图片文件夹的路径\n",
    "\n",
    "transform = T.Compose([T.Resize([224, 224]), \n",
    "                       T.ToTensor(), \n",
    "                       T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])\n",
    "donkey_dataset = DonkeyDataset(root=root, label=label, transform=transform, register=True)  # 使用ToTensor将图像转换为张量\n",
    "\n",
    "# 测试函数\n",
    "def test_dataset(dataset):\n",
    "    print(\"Testing dataset...\")\n",
    "    \n",
    "    try:\n",
    "        # 检查长度\n",
    "        assert len(dataset) == len(os.listdir(root)), \"Dataset length mismatch.\"\n",
    "\n",
    "        # 测试前3个样本\n",
    "        for i in range(3):\n",
    "            img, label = dataset[i]\n",
    "            # 检查图像和标签是否存在\n",
    "            assert img is not None, f\"Image at index {i} is None.\"\n",
    "            assert label is not None, f\"Label at index {i} is None.\"\n",
    "            #print(f\"Sample {i}: Image size - {img.size() if hasattr(img, 'size') else img.shape}, Label - {label}\")\n",
    "        \n",
    "        print(\"Dataset test passed successfully!\")\n",
    "    except AssertionError as e:\n",
    "        print(\"Dataset test failed:\", e)\n",
    "\n",
    "# 运行测试\n",
    "test_dataset(donkey_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleDeepFeatures:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        batch_size: int = 128,\n",
    "        num_workers: int = 1,\n",
    "        device: str = \"cpu\",\n",
    "    ):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.device = device\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, dataset):\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model = self.model.eval()\n",
    "\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            num_workers=self.num_workers,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        outputs = []\n",
    "        label_list = []\n",
    "        for image, label in tqdm(loader, mininterval=1, ncols=100):\n",
    "            label_list.append(label)\n",
    "            with torch.no_grad():\n",
    "                output = self.model(image.to(self.device))\n",
    "                outputs.append(output.cpu())\n",
    "                \n",
    "        return torch.cat(outputs).numpy(), label_list\n",
    "\n",
    "    def run_and_save(self, dataset, save_path):\n",
    "        features = self(dataset)\n",
    "\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        name = self.__class__.__name__\n",
    "        data = {\n",
    "        \"name\": name,\n",
    "        \"features\": features,\n",
    "        \"metadata\": getattr(dataset, \"metadata\", None),\n",
    "        }\n",
    "\n",
    "        file_name = os.path.join(save_path, name + \".pkl\")\n",
    "        with open(file_name, \"wb\") as file:\n",
    "            pickle.dump(data, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "PIL.Image.MAX_IMAGE_PIXELS = None\n",
    "name = 'hf-hub:BVRA/MegaDescriptor-T-224'\n",
    "model = timm.create_model(name, num_classes=0, pretrained=True)\n",
    "extractor = SimpleDeepFeatures(model)\n",
    "features, labels = extractor(donkey_dataset)\n",
    "print(features.shape)\n",
    "merged_list = [item for sublist in labels for item in sublist]\n",
    "\n",
    "# 保存到 .npy 文件\n",
    "#np.save('features.npy', features)\n",
    "np.savez('features_and_labels.npz', features=features, labels=merged_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data = np.load('features_and_labels.npz')\n",
    "features = data['features']\n",
    "merged_list = data['labels']\n",
    "print(features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "class SimpleKnnClassifier:\n",
    "    def __init__(self, database_labels, k: int = 1):\n",
    "        self.k = k\n",
    "        self.database_labels = np.array(database_labels)\n",
    "\n",
    "    def __call__(self, similarity):\n",
    "\n",
    "        similarity = torch.tensor(similarity, dtype=float)\n",
    "        scores, idx = similarity.topk(k=self.k, dim=0)\n",
    "        pred = self.aggregate(idx)[:, self.k - 1]\n",
    "        if self.database_labels is not None:\n",
    "            pred = self.database_labels[pred]\n",
    "        return pred\n",
    "\n",
    "    def aggregate(self, predictions):\n",
    "        \"\"\"\n",
    "        Aggregates array of nearest neighbours to single prediction for each k.\n",
    "        If there is tie at given k, prediction from k-1 is used.\n",
    "\n",
    "        Args:\n",
    "            array of with shape [n_query, k] of nearest neighbours.\n",
    "        Returns:\n",
    "            array with predictions [n_query, k]. Column dimensions are predictions for [k=1,...,k=k]\n",
    "        \"\"\"\n",
    "\n",
    "        results = []\n",
    "        # for k in range(1, predictions.shape[1] + 1):\n",
    "        for row in predictions:\n",
    "            vals, counts = np.unique(row, return_counts=True)\n",
    "            best = vals[np.argmax(counts)]\n",
    "\n",
    "            counts_sorted = sorted(counts)\n",
    "            if (len(counts_sorted)) > 1 and (counts_sorted[0] == counts_sorted[1]):\n",
    "                best = None\n",
    "            results.append(best)\n",
    "\n",
    "        results = pd.DataFrame(results).T.fillna(method=\"ffill\").T\n",
    "        return results.values\n",
    "\n",
    "\n",
    "class SimpleKnnMatcher:\n",
    "    \"\"\"\n",
    "    Find nearest match to query in existing database of features.\n",
    "    Combines CosineSimilarity and KnnClassifier.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, features, labels, k=1):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.classifier = SimpleKnnClassifier(\n",
    "            database_labels=self.labels, k=k\n",
    "        )\n",
    "\n",
    "    def __call__(self, query):\n",
    "        # if isinstance(query, list):\n",
    "        #     query = torch.cat(query)\n",
    "\n",
    "        # if not isinstance(query, np.ndarray):\n",
    "        #     raise ValueError(\"Query should be array or list of features.\")\n",
    "\n",
    "        sim_matrix = F.cosine_similarity(query, torch.tensor(self.features))\n",
    "\n",
    "        return sim_matrix\n",
    "        scores, idx = sim_matrix.topk(k=1, dim=0)\n",
    "        idx = idx.cpu().numpy()[0]\n",
    "        return self.labels[idx]\n",
    "        #return self.classifier(sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def yolo_to_pixel(bbox, img_width, img_height):\n",
    "    x_center, y_center, w, h = bbox\n",
    "\n",
    "    # 反归一化为像素坐标\n",
    "    x_center *= img_width\n",
    "    y_center *= img_height\n",
    "    w *= img_width\n",
    "    h *= img_height\n",
    "\n",
    "    # 计算像素坐标边界框 (x_min, y_min, x_max, y_max)\n",
    "    x_min = x_center - w / 2\n",
    "    y_min = y_center - h / 2\n",
    "    x_max = x_center + w / 2\n",
    "    y_max = y_center + h / 2\n",
    "\n",
    "    # 确保坐标在图像范围内\n",
    "    x_min = max(0, min(img_width, round(x_min)))\n",
    "    y_min = max(0, min(img_height, round(y_min)))\n",
    "    x_max = max(0, min(img_width, round(x_max)))\n",
    "    y_max = max(0, min(img_height, round(y_max)))\n",
    "\n",
    "    return x_min, y_min, x_max, y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import sys\n",
    "from PIL import Image\n",
    "import PIL\n",
    "PIL.Image.MAX_IMAGE_PIXELS = None\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "image_path = \"/data/Elio/data/Donkeys/trainset/origin_Data/images\"\n",
    "label_path = \"/data/Elio/data/Donkeys/donkey_labels_rec\"\n",
    "answer_txt_path = \"/data/Elio/data/Donkeys/donkey_labels_rec/classes.txt\"\n",
    "success = 0\n",
    "total = 0\n",
    "\n",
    "for i in tqdm(os.listdir(image_path)):\n",
    "    total += 1\n",
    "    image = Image.open(os.path.join(image_path, i))\n",
    "    width, height = image.size\n",
    "\n",
    "    label_name = i.split('.')[0] + '.txt'\n",
    "    label_txt = os.path.join(os.path.join(label_path, label_name))\n",
    "\n",
    "    with open(label_txt, 'r') as file:\n",
    "        for line in file:\n",
    "            # 解析每一行的数据\n",
    "            values = line.strip().split()\n",
    "            class_id = int(values[0])  # 第一个数是类别\n",
    "            bbox = list(map(float, values[1:5]))  # 后四个数是边框坐标\n",
    "            #print(f\"Class ID: {class_id}, Bounding Box: {bbox}\")\n",
    "    \n",
    "    # 获取答案\n",
    "    answer_list = []\n",
    "    with open(answer_txt_path, 'r') as file:\n",
    "        for line in file:\n",
    "            answer_list.append(line)\n",
    "\n",
    "    answer = answer_list[class_id]\n",
    "    print('answer is: ', answer)\n",
    "    \n",
    "    x_min, y_min, x_max, y_max = yolo_to_pixel(bbox, width, height)\n",
    "\n",
    "    # 裁剪原图中的边界框区域\n",
    "    cropped_image = image.crop((x_min, y_min, x_max, y_max))\n",
    "    #cropped_image.save(i)\n",
    "\n",
    "    # 应用图像变换\n",
    "    query = model(transform(cropped_image).unsqueeze(0))\n",
    "    sim_matrix = F.cosine_similarity(query, torch.tensor(features))\n",
    "    #matcher = SimpleKnnMatcher(features, merged_list, k=1)\n",
    "    #res = matcher(query)\n",
    "\n",
    "    # 创建一个字典来存储每个类的得分\n",
    "    class_scores = defaultdict(list)\n",
    "\n",
    "    # 将得分归类\n",
    "    for idx, score in enumerate(sim_matrix):\n",
    "        class_name = merged_list[idx]  # 获取当前索引对应的类名\n",
    "        class_name = class_name.split('_')[0]\n",
    "        class_scores[class_name].append(score.item())\n",
    "\n",
    "    # 计算每个类的平均分\n",
    "    class_avg_scores = {cls: sum(scores) / len(scores) for cls, scores in class_scores.items()}\n",
    "    print(class_avg_scores)\n",
    "\n",
    "    # 找到平均分最高的类\n",
    "    final_class = max(class_avg_scores, key=class_avg_scores.get)\n",
    "    print(final_class)\n",
    "    sys.exit()\n",
    "    res = res.split('_')[0]\n",
    "\n",
    "    if answer.strip() == res.strip():\n",
    "        success += 1\n",
    "\n",
    "\n",
    "print(success / total)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
